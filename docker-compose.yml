version: '3.9'

services:
  # Database Service Creation
  postgres:
    image: postgres
    container_name: etl_db
    env_file:
      - .env
    ports:
      - 5432:5432
    volumes:
      - ~/apps/etl_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_PASSWORD=${ETL_PASSWORD}
      - POSTGRES_USER=${ETL_USER}
      - POSTGRES_DB=etl_db

  # Airlfow Service Creation
  airflow:
    image: apache/airflow
    container_name: etl_airflow
    environment:
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgres+psycopg2://${ETL_USER}:${ETL_PASSWORD}@postgres:5432/etl_db
    - AIRFLOW__WEBSERVER__SECRET_KEY={AIRFLOW_SECRET_KEY}
    - AIRFLOW__WEBSERVER__RBAC=True
    - AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
    - AIRFLOW__API__AUTH_BACKEND=airflow.api.auth.backend.basic_auth
    depends_on:
    - postgres
    ports:
    - "8080:8080"
    volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/scripts/sql:/opt/airflow/scripts
    - airflow_logs:/opt/airflow/logs
    - ./airflow/data:/opt/airflow/data
    - ./airflow/configs:/opt/airflow/configs
    - ./airflow/dags/utils:/opt/airflow/dags/utils
    command: >
      bash -c "airflow db init && 
      pip install pycountry &&
      airflow webserver & airflow scheduler"

  # Flask App Creation for API
  flask-app:
    container_name: etl_flask
    image: python:3.9-slim 
    ports:
      - "5001:5000"
    volumes:
      - ./app:/app  
    working_dir: /app 
    command: bash -c "pip install -r requirements.txt && flask run --host=0.0.0.0"  
    environment:
      - FLASK_APP=app.py
      - FLASK_RUN_HOST=0.0.0.0

  # Jupyter Service for better dependency control
  jupyter:
    container_name: etl_jupyter
    build:
      context: ./jupyter
    ports:
      - "8888:8888"
    volumes:
      - ./jupyter/notebooks:/home/jovyan/work
    environment:
      - JUPYTER_ENABLE_LAB=yes

volumes:
  airflow_logs: